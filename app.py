import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime

# [1] ì‹œìŠ¤í…œ ì„¤ì • ë° ë³´ì•ˆ
st.set_page_config(
    page_title="J-TECH Intelligence",
    page_icon="ğŸ“¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# [2] ê°€ë…ì„± ì¤‘ì‹¬ UI ë””ìì¸ (ê¸€ì”¨ì²´ ë° ëŒ€ë¹„ ê°•í™”)
st.markdown("""
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;700&display=swap');
    
    html, body, [class*="css"] { font-family: 'Pretendard', sans-serif; }
    
    /* ë°°ê²½ìƒ‰ ë° í°íŠ¸ ê°€ë…ì„± ìµœì í™” */
    .stApp { background-color: #0d1117; color: #e6edf3; }
    
    /* ì‚¬ì´ë“œë°” ì¼ì²´í™” */
    [data-testid="stSidebar"] {
        background-color: #161b22 !important;
        border-right: 1px solid #30363d;
    }

    /* ë‰´ìŠ¤ ì¹´ë“œ: ê¸€ì”¨ê°€ ì˜ ë³´ì´ë„ë¡ ë°°ê²½ê³¼ í°íŠ¸ ëŒ€ë¹„ ìƒí–¥ */
    .news-wrapper {
        background-color: #1c2128;
        padding: 22px;
        border-radius: 12px;
        border: 1px solid #444c56;
        margin-bottom: 18px;
        transition: 0.2s;
    }
    .news-wrapper:hover { border-color: #58a6ff; background-color: #22272e; }
    
    /* ë‰´ìŠ¤ ì œëª©: ë°ì€ íŒŒë€ìƒ‰ìœ¼ë¡œ ê°€ë…ì„± í™•ë³´ */
    .news-title {
        font-size: 1.25rem;
        font-weight: 700;
        color: #79c0ff !important;
        text-decoration: none;
        line-height: 1.5;
    }
    .news-tag {
        display: inline-block;
        padding: 3px 10px;
        border-radius: 5px;
        background-color: #238636;
        color: #ffffff;
        font-size: 0.8rem;
        font-weight: bold;
        margin-bottom: 10px;
    }
    .news-date { color: #8b949e; font-size: 0.9rem; margin-top: 10px; }

    /* ë©”íŠ¸ë¦­(ì§€í‘œ) ê¸€ì í¬ê¸° ìƒí–¥ */
    [data-testid="stMetricValue"] { font-size: 1.8rem !important; font-weight: 700 !important; color: #ffffff !important; }
    [data-testid="stMetricLabel"] { font-size: 1rem !important; color: #8b949e !important; }

    /* ê´‘ê³  ì—¬ë°± (í…ìŠ¤íŠ¸ ì œê±°) */
    .ad-spacer { height: 100px; margin: 20px 0; background: transparent; }
    </style>
    """, unsafe_allow_html=True)

# [3] ë°ì´í„° ì—”ì§„ (ìˆ˜ì§‘ ì‹¤íŒ¨ ë°©ì§€ ë¡œì§ ê°•í™”)
@st.cache_data(ttl=300)
def fetch_industry_news(keyword):
    # êµ¬ê¸€ ë‰´ìŠ¤ RSS URL (ì•ˆì „í•œ ì¿¼ë¦¬ ë°©ì‹)
    url = f"https://news.google.com/rss/search?q={keyword}&hl=ko&gl=KR&ceid=KR:ko"
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
    
    try:
        r = requests.get(url, headers=headers, timeout=15)
        soup = BeautifulSoup(r.text, 'xml')
        items = soup.find_all('item')
        
        if not items: # ë§Œì•½ RSS ê²°ê³¼ê°€ ë¹„ì–´ìˆìœ¼ë©´ ì¼ë°˜ ê²€ìƒ‰ ì‹œë„
            return pd.DataFrame()
            
        data = []
        for item in items[:12]:
            data.append({
                "title": item.title.text,
                "link": item.link.text,
                "date": item.pubDate.text[:16]
            })
        return pd.DataFrame(data)
    except:
        return pd.DataFrame()

def main():
    # --- ì‚¬ì´ë“œë°” ---
    with st.sidebar:
        st.markdown("<h2 style='color:#79c0ff;'>ğŸ’ J-TECH Insight</h2>", unsafe_allow_html=True)
        st.divider()
        category = st.radio(
            "ğŸ“ ì¹´í…Œê³ ë¦¬ ì„ íƒ",
            ["ì›ìì¬ ì‹œí™©", "ê¸€ë¡œë²Œ ë¬¼ë¥˜", "ì „ê¸°ì°¨ ì‚°ì—…", "IT/ë°˜ë„ì²´"]
        )
        st.divider()
        st.caption(f"ì‹œìŠ¤í…œ ê°€ë™ ì¤‘ | {datetime.now().strftime('%Y-%m-%d')}")

    # --- ë©”ì¸ ì»¨í…ì¸  ---
    st.markdown(f"<h1 style='color: white;'>ğŸ“¡ {category} ì‹¤ì‹œê°„ ë¦¬í¬íŠ¸</h1>", unsafe_allow_html=True)
    
    # ì§€í‘œ ì„¹ì…˜ (ê°€ë…ì„± ê°•í™”ëœ ë²„ì „)
    m1, m2, m3, m4 = st.columns(4)
    m1.metric("LME êµ¬ë¦¬", "$9,415", "-0.8%")
    m2.metric("í™˜ìœ¨(USD)", "1,384.5", "â–² 2.1")
    m3.metric("ë‚˜ìŠ¤ë‹¥", "15,820", "+0.4%")
    m4.metric("ìœ ê°€(WTI)", "$76.12", "â–¼ 0.5%")

    # ê´‘ê³ ìš© ë¹ˆ ê³µê°„
    st.markdown('<div class="ad-spacer"></div>', unsafe_allow_html=True)

    # ë‰´ìŠ¤ ì„¹ì…˜
    keywords = {
        "ì›ìì¬ ì‹œí™©": "êµ¬ë¦¬ ì•Œë£¨ë¯¸ëŠ„ ì›ìì¬ ê°€ê²©",
        "ê¸€ë¡œë²Œ ë¬¼ë¥˜": "í•´ìš´ ë¬¼ë¥˜ ê³µê¸‰ë§ ì´ìŠˆ",
        "ì „ê¸°ì°¨ ì‚°ì—…": "ì „ê¸°ì°¨ ë°°í„°ë¦¬ ë¦¬íŠ¬ ì†Œì¬",
        "IT/ë°˜ë„ì²´": "ë°˜ë„ì²´ ì‹œì¥ ìˆ˜ê¸‰ ì „ë§"
    }

    with st.spinner("ìµœì‹  ë°ì´í„°ë¥¼ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
        df = fetch_industry_news(keywords[category])
        
        if not df.empty:
            col1, col2 = st.columns(2)
            for idx, row in df.iterrows():
                target_col = col1 if idx % 2 == 0 else col2
                with target_col:
                    st.markdown(f"""
                        <div class="news-wrapper">
                            <div class="news-tag">{category}</div>
                            <a href="{row['link']}" target="_blank" class="news-title">{row['title']}</a>
                            <div class="news-date">ğŸ—“ {row['date']}</div>
                        </div>
                    """, unsafe_allow_html=True)
        else:
            # ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ ì•ˆë‚´
            st.error("âš ï¸ ë‰´ìŠ¤ ì„œë²„ì™€ì˜ ì—°ê²°ì´ ì ì‹œ ì§€ì—°ë˜ê³  ìˆìŠµë‹ˆë‹¤. 1~2ë¶„ í›„ ìƒˆë¡œê³ ì¹¨(F5) í•´ì£¼ì„¸ìš”.")
            st.info("ë°ì´í„° ì†ŒìŠ¤: Google News RSS")

if __name__ == "__main__":
    main()